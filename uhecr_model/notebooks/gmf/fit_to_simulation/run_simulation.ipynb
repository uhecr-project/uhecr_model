{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Comparison of arrival direction and joint models\n",
    "\n",
    "In order to verify the model is working, we fit simulations made under the assumptions of the model. We also compare the differences between a model for only the UHECR arrival directions and one for both the UHECR arrival directions and energies.\n",
    "<br>\n",
    "<br>\n",
    "*This code is used to produce the data shown in Figures 6, 7 and 8 (left panel) in Capel & Mortlock (2019).*  \n",
    "*See the separate notebook in this directory for the actual plotting of figures.*"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import h5py\n",
    "from matplotlib import pyplot as plt\n",
    "from pandas import DataFrame\n",
    "\n",
    "from fancy import Data, Model, Analysis\n",
    "from fancy.interfaces.stan import get_simulation_input"
   ],
   "outputs": [],
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-01T13:34:26.049021Z",
     "start_time": "2019-02-01T13:34:23.678075Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "'''Setting up'''\n",
    "\n",
    "# Define location of Stan files\n",
    "stan_path = '../../../stan/'\n",
    "\n",
    "# Define file containing source catalogue information\n",
    "source_file = '../../../data/sourcedata.h5'\n",
    "\n",
    "# make output directory if it doesnt exist\n",
    "if not os.path.isdir(\"output\"):\n",
    "    os.mkdir(\"output\")\n",
    "\n",
    "# source_types = [\"SBG_23\", \"2FHL_250Mpc\", \"swift_BAT_213\"]\n",
    "source_types = [\"SBG_23\"]\n",
    "\n",
    "# detector_types = [\"auger2010\", \"auger2014\", \"TA2015\"]\n",
    "# detector_type = \"auger2014\"\n",
    "# detector_types = [\"TA2015\", \"auger2014\"]\n",
    "detector_types = [\"TA2015\"]\n",
    "\n",
    "# set random seed\n",
    "# random_seeds = [19990308, 4968460, 165490]\n",
    "random_seeds = [19990308]\n",
    "# random_seeds = [19990308, 4968460, 165490, 87, 7984165, 168490, 9874651, 980, 546, 7984, 333, 2]\n",
    "# random_seed = 165490849\n",
    "\n",
    "# flag to control showing plots or not\n",
    "show_plot = True\n",
    "\n",
    "ptypes = [\"p\"]\n",
    "\n",
    "tightB_label = \"normal\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "'''Create joint simulated dataset'''\n",
    "\n",
    "# Define a Stan simulation to run\n",
    "sim_name = stan_path + 'joint_gmf_model_sim.stan' # simulate all processes\n",
    "# sim_name = stan_path + 'joint_model_sim.stan' # simulate all processes\n",
    "# Define simulation using Model object and compile Stan code if necessary\n",
    "simulation = Model(sim_filename = sim_name, include_paths = stan_path)\n",
    "simulation.compile(reset=False)\n",
    "\n",
    "for detector_type in detector_types:\n",
    "    '''set detector and detector properties'''\n",
    "    if detector_type == \"TA2015\":\n",
    "        from fancy.detector.TA2015 import detector_properties, alpha_T, M, Eth\n",
    "    elif detector_type == \"auger2014\":\n",
    "        from fancy.detector.auger2014 import detector_properties, alpha_T, M, Eth\n",
    "    elif detector_type == \"auger2010\":\n",
    "        from fancy.detector.auger2010 import detector_properties, alpha_T, M, Eth\n",
    "    else:\n",
    "        raise Exception(\"Undefined detector type!\")\n",
    "        \n",
    "    for ptype in ptypes:\n",
    "        for random_seed in random_seeds:\n",
    "            for source_type in source_types:\n",
    "                print(\"Current Source: {0} {1} {2} {3}\".format(source_type, detector_type, ptype, random_seed))\n",
    "                # define separate files\n",
    "                table_file = '../../../tables/tables_{0}_{1}.h5'.format(source_type, detector_type)\n",
    "                sim_output_file = 'output/joint_gmf_model_simulation_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "\n",
    "                # Define a source catalogue and detector exposure\n",
    "                # In the paper we use the SBG catalogue\n",
    "                data = Data()\n",
    "                data.add_source(source_file, source_type)\n",
    "                data.add_detector(detector_properties)\n",
    "\n",
    "                # Plot the sources in Galactic coordinates\n",
    "                # if show_plot:\n",
    "                #     data.show();\n",
    "\n",
    "                # Define associated fraction\n",
    "                f = 0.5 \n",
    "\n",
    "                # Simulation input\n",
    "                B = 20 # nG\n",
    "                alpha = 3.0\n",
    "                # B = 15\n",
    "                # alpha = 6\n",
    "                Eth = Eth   \n",
    "                Eth_sim = 20 # EeV\n",
    "                ptype = ptype  # assume proton\n",
    "\n",
    "                # number of simulated inputs\n",
    "                # changes the background flux linearly\n",
    "                # should choose Nsim such that FT is the same for\n",
    "                # each observatory\n",
    "                # this ensures that L, F0 are the same\n",
    "                # \n",
    "                # for PAO, we saw that FT, detector_type = 0.3601\n",
    "                # FT_PAO = 0.3601   # total, detector_type flux using {1} data with Nsim = 2500, detector_type\n",
    "                # Nsim_expected = FT_PAO / (M / alpha_T)\n",
    "                # Nsim = int(np.round(Nsim_expected))\n",
    "\n",
    "                Nsim = 2500\n",
    "\n",
    "                # check value for Nsim\n",
    "                print(\"Simulated events: {0}\".format(Nsim))\n",
    "\n",
    "\n",
    "                # L in yr^-1, F in km^-2 yr^-1\n",
    "                L, F0 = get_simulation_input(Nsim, f, data.source.distance, M, alpha_T)\n",
    "\n",
    "                # To scale between definition of flux in simulations and fits\n",
    "                flux_scale = (Eth / Eth_sim)**(1 - alpha)\n",
    "\n",
    "                simulation.input(B = B, L = L, F0 = F0,\n",
    "                            alpha = alpha, Eth = Eth, ptype=ptype)\n",
    "\n",
    "                # check luminosity and isotropic flux values\n",
    "                # L ~ O(10^39), F0 ~ 0.18\n",
    "                # same luminosity so only need to check one value\n",
    "                print(\"Simulated Luminosity: {0:.3e}\".format(L[0]))\n",
    "                print(\"Simulated isotropic flux: {0:.3f}\".format(F0))\n",
    "\n",
    "\n",
    "                # What is happening \n",
    "                summary = b'Simulation using the joint model and SBG catalogue' # must be a byte str\n",
    "                    \n",
    "                # Define an Analysis object to bring together Data and Model objects\n",
    "                # sim_analysis = Analysis(data, simulation, analysis_type = 'joint_gmf', \n",
    "                #                     filename = sim_output_file, summary = summary)\n",
    "\n",
    "                sim_analysis = Analysis(data, simulation, analysis_type = 'joint_gmf', \n",
    "                                    filename = sim_output_file, summary = summary)\n",
    "\n",
    "                print(\"Building tables...\")\n",
    "\n",
    "                # Build pre-computed values for the simulation as you go\n",
    "                # So that you can try out different parameters\n",
    "                sim_analysis.build_tables(sim_only = True)\n",
    "\n",
    "                print(\"Running simulation...\")\n",
    "                # Run simulation\n",
    "                sim_analysis.simulate(seed = random_seed, Eth_sim = Eth_sim)\n",
    "\n",
    "                # Save to file \n",
    "                sim_analysis.save()\n",
    "\n",
    "                # print resulting UHECR observed after propagation and Elosses\n",
    "                print(\"Observed simulated UHECRs: {0}\\n\".format(sim_analysis.N))\n",
    "\n",
    "\n",
    "                # print plots if flag is set to true\n",
    "                # if show_plot:\n",
    "                #     sim_analysis.plot(\"arrival_direction\");\n",
    "                    # sim_analysis.plot(\"energy\");"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cached StanModel\n",
      "Current Source: SBG_23 TA2015 p 19990308\n",
      "Simulated events: 2500\n",
      "Simulated Luminosity: 1.858e+40\n",
      "Simulated isotropic flux: 0.997\n",
      "Building tables...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Precomputing exposure integral: 100%|██████████| 23/23 [00:05<00:00,  4.02it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Running simulation...\n",
      "Running Stan simulation...\n",
      "Extracting output...\n",
      "Simulating deflections...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Adding UHECR to Map Container: 100%|██████████| 1397/1397 [04:31<00:00,  5.14it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Performing truncations due to exposure...\n",
      "Simulating zenith angles...\n",
      "Computing kappa_gmf...\n",
      "Done!\n",
      "Observed simulated UHECRs: 164\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "'''Fit using arrival direction model'''\n",
    "for detector_type in detector_types:\n",
    "    for ptype in ptypes:\n",
    "        for random_seed in random_seeds:\n",
    "            for source_type in source_types:\n",
    "                print(\"Current Source: {0}\".format(source_type))\n",
    "                # define separate files\n",
    "                table_file = '../../../tables/tables_{0}_{1}.h5'.format(source_type, detector_type)\n",
    "                sim_output_file = 'output/joint_gmf_model_simulation_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "                arrival_output_file = 'output/arrival_direction_fit_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "                # joint_output_file = 'output/joint_fit_{0}_PAO.h5'.format(source_type)\n",
    "\n",
    "                # Define data from simulation\n",
    "                data = Data()\n",
    "                data.from_file(sim_output_file)\n",
    "\n",
    "                # if show_plot:\n",
    "                #     data.show()\n",
    "\n",
    "                # Arrival direction model\n",
    "                model_name = stan_path + 'arrival_direction_model.stan'\n",
    "\n",
    "                # Compile\n",
    "                model = Model(model_filename = model_name, include_paths = stan_path)\n",
    "                model.compile(reset=False)\n",
    "\n",
    "                # Define threshold energy in EeV\n",
    "                model.input(Eth = Eth)\n",
    "\n",
    "                # What is happening \n",
    "                summary = b'Fit of the arrival direction model to the joint simulation' \n",
    "                    \n",
    "                # Define an Analysis object to bring together Data and Model objects\n",
    "                analysis = Analysis(data, model, analysis_type = 'joint', \n",
    "                                    filename = arrival_output_file, summary = summary)\n",
    "\n",
    "                # Define location of pre-computed values used in fits \n",
    "                # (see relevant notebook for how to make these files) \n",
    "                # Each catalogue has a file of pre-computed values\n",
    "                analysis.use_tables(table_file)\n",
    "\n",
    "                # Fit the Stan model\n",
    "                fit = analysis.fit_model(chains = 16, iterations = 500, seed = random_seed)\n",
    "\n",
    "                # Save to analysis file\n",
    "                analysis.save()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Source: SBG_23\n",
      "Using cached StanModel\n",
      "Performing fitting...\n",
      "Checking all diagnostics...\n",
      "Done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "'''Fit using joint model'''\n",
    "for detector_type in detector_types:\n",
    "    for ptype in ptypes:\n",
    "        for random_seed in random_seeds:\n",
    "            for source_type in source_types:\n",
    "                print(\"Current Source: {0}\".format(source_type))\n",
    "                # define separate files\n",
    "                table_file = '../../../tables/tables_{0}_{1}.h5'.format(source_type, detector_type)\n",
    "                sim_output_file = 'output/joint_gmf_model_simulation_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "                # arrival_output_file = 'output/arrival_direction_fit_{0}_{1}_{2}_{3}.h5'.format(source_type, detector_type, random_seed, ptype)\n",
    "                joint_output_file = 'output/joint_fit_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "\n",
    "                # Define data from simulation\n",
    "                data = Data()\n",
    "                data.from_file(sim_output_file)\n",
    "\n",
    "                # create Model and compile \n",
    "                model_name = stan_path + 'joint_model.stan'\n",
    "                model = Model(model_filename = model_name, include_paths = stan_path)\n",
    "                model.compile(reset=False)\n",
    "                model.input(Eth = Eth)\n",
    "\n",
    "                # create Analysis object\n",
    "                summary = b'Fit of the joint model to the joint + gmf simulation' \n",
    "                analysis = Analysis(data, model, analysis_type = 'joint', \n",
    "                                    filename = joint_output_file, summary = summary)\n",
    "                analysis.use_tables(table_file)\n",
    "\n",
    "                # Fit the Stan model\n",
    "                fit = analysis.fit_model(chains = 16, iterations = 500, seed = random_seed)\n",
    "\n",
    "                # Save to analysis file\n",
    "                analysis.save()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Source: SBG_23\n",
      "Using cached StanModel\n",
      "Performing fitting...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Checking all diagnostics...\n",
      "Done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "'''Fit using joint + gmf model'''\n",
    "for detector_type in detector_types:\n",
    "    for ptype in ptypes:\n",
    "        for random_seed in random_seeds:\n",
    "            for source_type in source_types:\n",
    "                print(\"Current Source: {0}\".format(source_type))\n",
    "                # define separate files\n",
    "                table_file = '../../../tables/tables_{0}_{1}.h5'.format(source_type, detector_type)\n",
    "                sim_output_file = 'output/joint_gmf_model_simulation_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "                # arrival_output_file = 'output/arrival_direction_fit_{0}_{1}_{2}_{4}.h5'.format(source_type, detector_type, random_seed, ptype)\n",
    "                joint_gmf_output_file = 'output/joint_gmf_fit_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "\n",
    "                # Define data from simulation\n",
    "                data = Data()\n",
    "                data.from_file(sim_output_file)\n",
    "\n",
    "                print(type(data.uhecr.ptype))\n",
    "                print(isinstance(data.uhecr.ptype, bytes))\n",
    "                # print(data.uhecr.ptype.decode('UTF-8'))\n",
    "\n",
    "                # create Model and compile \n",
    "                model_name = stan_path + 'joint_gmf_model.stan'\n",
    "                model = Model(model_filename = model_name, include_paths = stan_path)\n",
    "                model.compile(reset=False)\n",
    "                model.input(Eth = Eth)\n",
    "\n",
    "                # create Analysis object\n",
    "                summary = b'Fit of the joint + gmf model to the joint + gmf simulation' \n",
    "                analysis = Analysis(data, model, analysis_type = 'joint_gmf', \n",
    "                                    filename = joint_gmf_output_file, summary = summary)\n",
    "\n",
    "                # print(analysis.ptype)\n",
    "                analysis.use_tables(table_file)\n",
    "\n",
    "                # Fit the Stan model\n",
    "                fit = analysis.fit_model(chains = 16, iterations = 500, seed = random_seed)\n",
    "\n",
    "                # Save to analysis file\n",
    "                analysis.save()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Source: SBG_23\n",
      "<class 'str'>\n",
      "False\n",
      "Using cached StanModel\n",
      "Performing fitting...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
      "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Checking all diagnostics...\n",
      "Done!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "'''Fit using joint + gmf model'''\n",
    "for detector_type in detector_types:\n",
    "    for ptype in ptypes:\n",
    "        for random_seed in random_seeds:\n",
    "            for source_type in source_types:\n",
    "                print(\"Current Source: {0}\".format(source_type))\n",
    "                # define separate files\n",
    "                table_file = '../../../tables/tables_{0}_{1}.h5'.format(source_type, detector_type)\n",
    "                sim_output_file = 'output/joint_gmf_model_simulation_{0}_{1}_{2}_{3}_{4}.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "                # arrival_output_file = 'output/arrival_direction_fit_{0}_{1}_{2}_{4}.h5'.format(source_type, detector_type, random_seed, ptype)\n",
    "                joint_gmf_output_file = 'output/joint_gmf_fit_{0}_{1}_{2}_{3}_{4}_boxB.h5'.format(source_type, detector_type, random_seed, ptype, tightB_label)\n",
    "\n",
    "                # Define data from simulation\n",
    "                data = Data()\n",
    "                data.from_file(sim_output_file)\n",
    "\n",
    "                print(type(data.uhecr.ptype))\n",
    "                print(isinstance(data.uhecr.ptype, bytes))\n",
    "                # print(data.uhecr.ptype.decode('UTF-8'))\n",
    "\n",
    "                # create Model and compile \n",
    "                model_name = stan_path + 'joint_gmf_model_boxB.stan'\n",
    "                model = Model(model_filename = model_name, include_paths = stan_path)\n",
    "                model.compile(reset=False)\n",
    "                model.input(Eth = Eth)\n",
    "\n",
    "                # create Analysis object\n",
    "                summary = b'Fit of the joint + gmf model to the joint + gmf simulation' \n",
    "                analysis = Analysis(data, model, analysis_type = 'joint_gmf', \n",
    "                                    filename = joint_gmf_output_file, summary = summary)\n",
    "\n",
    "                # print(analysis.ptype)\n",
    "                analysis.use_tables(table_file)\n",
    "\n",
    "                # Fit the Stan model\n",
    "                fit = analysis.fit_model(chains = 16, iterations = 500, seed = random_seed)\n",
    "\n",
    "                # Save to analysis file\n",
    "                analysis.save()\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Current Source: SBG_23\n",
      "<class 'str'>\n",
      "False\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../stan/joint_gmf_model_boxB.stan'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-600c72e937f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstan_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'joint_gmf_model_boxB.stan'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstan_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/uhecr_project/fancy/fancy/interfaces/stan.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, reset)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m             self.model = stan_utility.compile_model(\n\u001b[0m\u001b[1;32m     44\u001b[0m                 \u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/devel/uhecr_project/stan_utility/stan_utility/utils.py\u001b[0m in \u001b[0;36mcompile_model\u001b[0;34m(filename, model_name, print_code, reset, **kwargs)\u001b[0m\n\u001b[1;32m    247\u001b[0m     See http://pystan.readthedocs.io/en/latest/avoiding_recompilation.html\"\"\"\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0mmodel_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../stan/joint_gmf_model_boxB.stan'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed88844adb047a7086eb0ff0e5bdcb90f4ec22b1fadf7c68769e3dcdb7b75680"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('cartopy': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}